{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "AT5OogJVFbwu",
   "metadata": {
    "id": "AT5OogJVFbwu"
   },
   "source": [
    "# ExtraaLearn Project\n",
    "\n",
    "## Context\n",
    "\n",
    "The EdTech industry has been surging in the past decade immensely, and according to a forecast, the Online Education market would be worth $286.62bn by 2023 with a compound annual growth rate (CAGR) of 10.26% from 2018 to 2023. The modern era of online education has enforced a lot in its growth and expansion beyond any limit. Due to having many dominant features like ease of information sharing, personalized learning experience, transparency of assessment, etc, it is now preferable to traditional education. \n",
    "\n",
    "In the present scenario due to the Covid-19, the online education sector has witnessed rapid growth and is attracting a lot of new customers. Due to this rapid growth, many new companies have emerged in this industry. With the availability and ease of use of digital marketing resources, companies can reach out to a wider audience with their offerings. The customers who show interest in these offerings are termed as leads. There are various sources of obtaining leads for Edtech companies, like\n",
    "\n",
    "* The customer interacts with the marketing front on social media or other online platforms. \n",
    "* The customer browses the website/app and downloads the brochure\n",
    "* The customer connects through emails for more information.\n",
    "\n",
    "The company then nurtures these leads and tries to convert them to paid customers. For this, the representative from the organization connects with the lead on call or through email to share further details.\n",
    "\n",
    "## Objective\n",
    "\n",
    "ExtraaLearn is an initial stage startup that offers programs on cutting-edge technologies to students and professionals to help them upskill/reskill. With a large number of leads being generated on a regular basis, one of the issues faced by ExtraaLearn is to identify which of the leads are more likely to convert so that they can allocate resources accordingly. You, as a data scientist at ExtraaLearn, have been provided the leads data to:\n",
    "* Analyze and build an ML model to help identify which leads are more likely to convert to paid customers, \n",
    "* Find the factors driving the lead conversion process\n",
    "* Create a profile of the leads which are likely to convert\n",
    "\n",
    "\n",
    "## Data Description\n",
    "\n",
    "The data contains the different attributes of leads and their interaction details with ExtraaLearn. The detailed data dictionary is given below.\n",
    "\n",
    "\n",
    "**Data Dictionary**\n",
    "* ID: ID of the lead\n",
    "* age: Age of the lead\n",
    "* current_occupation: Current occupation of the lead. Values include 'Professional','Unemployed',and 'Student'\n",
    "* first_interaction: How did the lead first interacted with ExtraaLearn. Values include 'Website', 'Mobile App'\n",
    "* profile_completed: What percentage of profile has been filled by the lead on the website/mobile app. Values include Low - (0-50%), Medium - (50-75%), High (75-100%)\n",
    "* website_visits: How many times has a lead visited the website\n",
    "* time_spent_on_website: Total time spent on the website\n",
    "* page_views_per_visit: Average number of pages on the website viewed during the visits.\n",
    "* last_activity: Last interaction between the lead and ExtraaLearn. \n",
    "    * Email Activity: Seeking for details about program through email, Representative shared information with lead like brochure of program , etc \n",
    "    * Phone Activity: Had a Phone Conversation with representative, Had conversation over SMS with representative, etc\n",
    "    * Website Activity: Interacted on live chat with representative, Updated profile on website, etc\n",
    "\n",
    "* print_media_type1: Flag indicating whether the lead had seen the ad of ExtraaLearn in the Newspaper.\n",
    "* print_media_type2: Flag indicating whether the lead had seen the ad of ExtraaLearn in the Magazine.\n",
    "* digital_media: Flag indicating whether the lead had seen the ad of ExtraaLearn on the digital platforms.\n",
    "* educational_channels: Flag indicating whether the lead had heard about ExtraaLearn in the education channels like online forums, discussion threads, educational websites, etc.\n",
    "* referral: Flag indicating whether the lead had heard about ExtraaLearn through reference.\n",
    "* status: Flag indicating whether the lead was converted to a paid customer or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-island",
   "metadata": {
    "id": "dirty-island"
   },
   "source": [
    "## Importing necessary libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "statewide-still",
   "metadata": {
    "id": "statewide-still"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Importing standard libraries\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msns\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Importing standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", 200)\n",
    "\n",
    "# Importing classification metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Importing classification models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Importing model selection and evaluation tools\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "\n",
    "# Helper functions for EDA (adapted for classification)\n",
    "def histogram_boxplot(data, feature, figsize=(12, 7), kde=False, bins=None):\n",
    "    \"\"\"\n",
    "    Boxplot and histogram combined for univariate analysis\n",
    "    \n",
    "    data: dataframe\n",
    "    feature: dataframe column\n",
    "    figsize: size of figure (default (12,7))\n",
    "    kde: whether to show the density curve (default False)\n",
    "    bins: number of bins for histogram (default None)\n",
    "    \"\"\"\n",
    "    f2, (ax_box2, ax_hist2) = plt.subplots(\n",
    "        nrows=2,      # Number of rows of the subplot grid = 2\n",
    "        sharex=True,  # x-axis will be shared among all subplots\n",
    "        gridspec_kw={\"height_ratios\": (0.25, 0.75)},\n",
    "        figsize=figsize,\n",
    "    )                   # Creating the 2 subplots\n",
    "    sns.boxplot(data=data, x=feature, ax=ax_box2, showmeans=True, color=\"violet\"\n",
    "    )                   # Boxplot will be created and a star will indicate the mean value of the column\n",
    "    sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2, bins=bins, palette=\"winter\"\n",
    "    ) if bins else sns.histplot(\n",
    "        data=data, x=feature, kde=kde, ax=ax_hist2\n",
    "    )                   # For histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].mean(), color=\"green\", linestyle=\"--\"\n",
    "    )                   # Add mean to the histogram\n",
    "    ax_hist2.axvline(\n",
    "        data[feature].median(), color=\"black\", linestyle=\"-\"\n",
    "    )                   # Add median to the histogram\n",
    "\n",
    "\n",
    "def stacked_barplot(data, predictor, target):\n",
    "    \"\"\"\n",
    "    Print the category counts and plot a stacked bar chart for classification analysis\n",
    "    \n",
    "    data: dataframe\n",
    "    predictor: independent variable (categorical feature)\n",
    "    target: target variable (classification target)\n",
    "    \"\"\"\n",
    "    count = data[predictor].nunique()\n",
    "    sorter = data[target].value_counts().index[-1]\n",
    "    tab1 = pd.crosstab(data[predictor], data[target], margins=True).sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    print(tab1)\n",
    "    print(\"-\" * 120)\n",
    "    tab = pd.crosstab(data[predictor], data[target], normalize=\"index\").sort_values(\n",
    "        by=sorter, ascending=False\n",
    "    )\n",
    "    tab.plot(kind=\"bar\", stacked=True, figsize=(count + 1, 5))\n",
    "    plt.legend(\n",
    "        loc=\"lower left\",\n",
    "        frameon=False,\n",
    "    )\n",
    "    plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n",
    "    plt.show()\n",
    "\n",
    "# Loading the leads dataset\n",
    "data = pd.read_csv(\"../data/ExtraaLearn.csv\")\n",
    "\n",
    "# Copying data to preserve original\n",
    "same_data = data.copy()\n",
    "\n",
    "print(\"Data loaded successfully!\")\n",
    "print(f\"Dataset shape: {data.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-infection",
   "metadata": {
    "id": "desperate-infection"
   },
   "source": [
    "## Data Overview\n",
    "\n",
    "- Observations\n",
    "- Sanity checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365111ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the shape of the data\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9507e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the info of the data\n",
    "data.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb47b0af",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Document actual data types, null counts, and memory usage\n",
    "- Note which columns are numeric vs categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bedd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Univariate Analysis - Numeric Features\n",
    "\n",
    "# Plotting numeric features using histogram_boxplot\n",
    "numeric_features = ['age', 'website_visits', 'time_spent_on_website', 'page_views_per_visit']\n",
    "\n",
    "for feature in numeric_features:\n",
    "    histogram_boxplot(data, feature, kde=True, bins=30)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ef2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the descriptive statistics of the numeric columns\n",
    "data.describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df845573",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing values\n",
    "print(\"Missing values in the dataset:\")\n",
    "print(data.isnull().sum())\n",
    "print(\"\\nTotal missing values:\", data.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbcfbab",
   "metadata": {},
   "source": [
    "**Univariate Analysis Observations:**\n",
    "\n",
    "- For each numeric feature plotted, document actual findings:\n",
    "  - Report exact outlier values found\n",
    "  - Note distribution shape (normal, skewed left/right, bimodal, etc.)\n",
    "  - Report mean, median, and any notable patterns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbe1049",
   "metadata": {},
   "source": [
    "**Missing Value Treatment:**\n",
    "\n",
    "- Document any missing values found and how they were handled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d893c86",
   "metadata": {},
   "source": [
    "**Decision Tree Model Performance:**\n",
    "\n",
    "- Report actual metrics: \"Decision Tree achieves Accuracy: X%, Precision: Y%, Recall: Z%, F1: W%\"\n",
    "- Display and interpret confusion matrix: \"The model correctly predicts [X] conversions and [Y] non-conversions. It has [Z] false positives and [W] false negatives.\"\n",
    "- Interpret model performance: \"The model shows [strength/weakness] in [specific metric], which is [important/less critical] for lead conversion prediction.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7701a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outlier Detection using IQR method for numeric columns\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "print(\"Outlier Detection (using IQR method):\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = data[col].quantile(0.25)\n",
    "    Q3 = data[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = data[(data[col] < lower_bound) | (data[col] > upper_bound)]\n",
    "    outlier_count = len(outliers)\n",
    "    \n",
    "    if outlier_count > 0:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Lower bound: {lower_bound:.2f}, Upper bound: {upper_bound:.2f}\")\n",
    "        print(f\"  Number of outliers: {outlier_count} ({outlier_count/len(data)*100:.2f}%)\")\n",
    "        print(f\"  Min value: {data[col].min()}, Max value: {data[col].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f72d90",
   "metadata": {},
   "source": [
    "**Outlier Treatment:**\n",
    "\n",
    "- Document outliers found and decision on treatment (keep, cap, remove) based on actual data analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e3665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-Hot Encoding for categorical variables\n",
    "print(\"Before encoding:\")\n",
    "print(f\"Number of columns: {len(data.columns)}\")\n",
    "print(f\"Data types:\\n{data.dtypes.value_counts()}\")\n",
    "\n",
    "# Get categorical columns\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "print(f\"\\nCategorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Perform one-hot encoding\n",
    "data_encoded = pd.get_dummies(\n",
    "    data,\n",
    "    columns=categorical_cols,\n",
    "    drop_first=True\n",
    ")\n",
    "\n",
    "print(f\"\\nAfter encoding:\")\n",
    "print(f\"Number of columns: {len(data_encoded.columns)}\")\n",
    "print(f\"Number of dummy variables created: {len(data_encoded.columns) - len(data.columns) + len(categorical_cols)}\")\n",
    "\n",
    "# Update data\n",
    "data = data_encoded.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a938aebd",
   "metadata": {},
   "source": [
    "**Encoding Summary:**\n",
    "\n",
    "- Report how many dummy variables were created\n",
    "- Report final feature count after encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb933c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for modeling\n",
    "# Separate independent variables and target\n",
    "X = data.drop('status', axis=1)\n",
    "y = data['status']\n",
    "\n",
    "print(f\"Features (X) shape: {X.shape}\")\n",
    "print(f\"Target (y) shape: {y.shape}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    shuffle=True, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain set - X: {X_train.shape}, y: {y_train.shape}\")\n",
    "print(f\"Test set - X: {X_test.shape}, y: {y_test.shape}\")\n",
    "print(f\"\\nTrain set target distribution:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(f\"\\nTest set target distribution:\")\n",
    "print(y_test.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf961ef5",
   "metadata": {},
   "source": [
    "**Train-Test Split Summary:**\n",
    "\n",
    "- Note train/test split ratio and sample sizes\n",
    "- Document target variable distribution in train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bivariate Analysis - Correlation Heatmap\n",
    "numeric_data = data.select_dtypes(include=[np.number])\n",
    "correlation_matrix = numeric_data.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', center=0, square=True)\n",
    "plt.title('Correlation Heatmap of Numeric Variables')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83412d",
   "metadata": {},
   "source": [
    "**Correlation Analysis Observations:**\n",
    "\n",
    "- Report actual correlation values\n",
    "- Note which numeric features show strongest correlation with conversion (if any)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803487d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: How does current_occupation affect lead status?\n",
    "print(\"=\" * 80)\n",
    "print(\"Question 1: How does current_occupation affect lead status?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stacked_barplot(data, \"current_occupation\", \"status\")\n",
    "\n",
    "# Calculate conversion rates for each occupation category\n",
    "occupation_conversion = data.groupby('current_occupation')['status'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "occupation_conversion.columns = ['Occupation', 'Total_Leads', 'Converted', 'Conversion_Rate']\n",
    "occupation_conversion['Conversion_Rate'] = occupation_conversion['Conversion_Rate'] * 100\n",
    "occupation_conversion = occupation_conversion.sort_values('Conversion_Rate', ascending=False)\n",
    "print(\"\\nConversion Rates by Occupation:\")\n",
    "print(occupation_conversion)\n",
    "\n",
    "# Create barplot showing conversion rates by occupation\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=occupation_conversion, x='Occupation', y='Conversion_Rate', palette='viridis')\n",
    "plt.title('Conversion Rate by Current Occupation')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xlabel('Current Occupation')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1bc906",
   "metadata": {},
   "source": [
    "**Question 1 Insights:**\n",
    "\n",
    "- Report actual conversion rates: \"Analysis reveals that [Occupation A] converts at [X]%, [Occupation B] converts at [Y]%, and [Occupation C] converts at [Z]%.\"\n",
    "- Identify which occupation has highest/lowest conversion with exact percentages\n",
    "- Provide interpretation: \"This [X-Y]% difference suggests [specific interpretation based on actual numbers and business context].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78620f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Do the first channels of interaction have an impact on lead status?\n",
    "print(\"=\" * 80)\n",
    "print(\"Question 2: Do the first channels of interaction have an impact on lead status?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stacked_barplot(data, \"first_interaction\", \"status\")\n",
    "\n",
    "# Calculate conversion rates for Website vs Mobile App\n",
    "first_interaction_conversion = data.groupby('first_interaction')['status'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "first_interaction_conversion.columns = ['First_Interaction', 'Total_Leads', 'Converted', 'Conversion_Rate']\n",
    "first_interaction_conversion['Conversion_Rate'] = first_interaction_conversion['Conversion_Rate'] * 100\n",
    "print(\"\\nConversion Rates by First Interaction Channel:\")\n",
    "print(first_interaction_conversion)\n",
    "\n",
    "# Create barplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=first_interaction_conversion, x='First_Interaction', y='Conversion_Rate', palette='Set2')\n",
    "plt.title('Conversion Rate by First Interaction Channel')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xlabel('First Interaction Channel')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734a79bd",
   "metadata": {},
   "source": [
    "**Question 2 Insights:**\n",
    "\n",
    "- Report actual conversion rates: \"Leads who first interacted via [Channel X] convert at [Y]%, while those via [Channel Z] convert at [W]%.\"\n",
    "- Calculate and report the difference: \"This represents a [X]% difference in conversion rates.\"\n",
    "- Provide business insight: \"This suggests [interpretation based on actual data].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1d24ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Which way of interaction works best?\n",
    "print(\"=\" * 80)\n",
    "print(\"Question 3: Which way of interaction works best?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stacked_barplot(data, \"last_activity\", \"status\")\n",
    "\n",
    "# Calculate conversion rates for Email Activity, Phone Activity, and Website Activity\n",
    "last_activity_conversion = data.groupby('last_activity')['status'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "last_activity_conversion.columns = ['Last_Activity', 'Total_Leads', 'Converted', 'Conversion_Rate']\n",
    "last_activity_conversion['Conversion_Rate'] = last_activity_conversion['Conversion_Rate'] * 100\n",
    "last_activity_conversion = last_activity_conversion.sort_values('Conversion_Rate', ascending=False)\n",
    "print(\"\\nConversion Rates by Last Activity:\")\n",
    "print(last_activity_conversion)\n",
    "\n",
    "# Create barplot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=last_activity_conversion, x='Last_Activity', y='Conversion_Rate', palette='muted')\n",
    "plt.title('Conversion Rate by Last Activity Type')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xlabel('Last Activity')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610b8c1d",
   "metadata": {},
   "source": [
    "**Question 3 Insights:**\n",
    "\n",
    "- Report actual conversion rates for each activity type: \"Email Activity: [X]%, Phone Activity: [Y]%, Website Activity: [Z]%.\"\n",
    "- Identify the most effective interaction method with exact percentage\n",
    "- Provide recommendation: \"Given that [Activity X] shows [Y]% conversion vs [Z]% average, we recommend [specific action based on actual data].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e54d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Which marketing channels have the highest lead conversion rate?\n",
    "print(\"=\" * 80)\n",
    "print(\"Question 4: Which marketing channels have the highest lead conversion rate?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate conversion rates for each media flag\n",
    "media_channels = {\n",
    "    'print_media_type1': 'Newspaper',\n",
    "    'print_media_type2': 'Magazine',\n",
    "    'digital_media': 'Digital platforms',\n",
    "    'educational_channels': 'Education channels',\n",
    "    'referral': 'Referrals'\n",
    "}\n",
    "\n",
    "channel_conversion_rates = []\n",
    "\n",
    "for col, name in media_channels.items():\n",
    "    # Convert Yes/No to 1/0 for calculation\n",
    "    data_temp = data.copy()\n",
    "    data_temp[col + '_encoded'] = (data_temp[col] == 'Yes').astype(int)\n",
    "    \n",
    "    # Calculate conversion rate for each channel\n",
    "    channel_stats = data_temp.groupby(col + '_encoded')['status'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "    channel_stats.columns = ['Channel_Flag', 'Total_Leads', 'Converted', 'Conversion_Rate']\n",
    "    \n",
    "    # Get conversion rate for channel = Yes (1)\n",
    "    if len(channel_stats) > 1:\n",
    "        conv_rate = channel_stats[channel_stats['Channel_Flag'] == 1]['Conversion_Rate'].values[0] * 100\n",
    "        total_leads = channel_stats[channel_stats['Channel_Flag'] == 1]['Total_Leads'].values[0]\n",
    "        converted = channel_stats[channel_stats['Channel_Flag'] == 1]['Converted'].values[0]\n",
    "    else:\n",
    "        conv_rate = 0\n",
    "        total_leads = 0\n",
    "        converted = 0\n",
    "    \n",
    "    channel_conversion_rates.append({\n",
    "        'Channel': name,\n",
    "        'Total_Leads': total_leads,\n",
    "        'Converted': converted,\n",
    "        'Conversion_Rate': conv_rate\n",
    "    })\n",
    "\n",
    "channel_df = pd.DataFrame(channel_conversion_rates).sort_values('Conversion_Rate', ascending=False)\n",
    "print(\"\\nConversion Rates by Marketing Channel:\")\n",
    "print(channel_df)\n",
    "\n",
    "# Create visualization comparing conversion rates across channels\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(data=channel_df, x='Channel', y='Conversion_Rate', palette='rocket')\n",
    "plt.title('Conversion Rate by Marketing Channel')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xlabel('Marketing Channel')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccccfc3e",
   "metadata": {},
   "source": [
    "**Question 4 Insights:**\n",
    "\n",
    "- Report actual conversion rates for each channel: \"[Channel X]: [Y]%, [Channel Z]: [W]%, etc.\"\n",
    "- Identify which channel has highest conversion with exact percentage\n",
    "- Provide recommendation: \"Given that [Channel X] shows [Y]% conversion vs [Z]% average, we recommend [specific marketing action based on actual data].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168141b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Does having more details about a prospect increase the chances of conversion?\n",
    "print(\"=\" * 80)\n",
    "print(\"Question 5: Does having more details about a prospect increase the chances of conversion?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "stacked_barplot(data, \"profile_completed\", \"status\")\n",
    "\n",
    "# Calculate conversion rates for Low, Medium, and High profile completion\n",
    "profile_conversion = data.groupby('profile_completed')['status'].agg(['count', 'sum', 'mean']).reset_index()\n",
    "profile_conversion.columns = ['Profile_Completed', 'Total_Leads', 'Converted', 'Conversion_Rate']\n",
    "profile_conversion['Conversion_Rate'] = profile_conversion['Conversion_Rate'] * 100\n",
    "\n",
    "# Order by profile completion level\n",
    "profile_order = ['Low', 'Medium', 'High']\n",
    "profile_conversion['Profile_Completed'] = pd.Categorical(profile_conversion['Profile_Completed'], categories=profile_order, ordered=True)\n",
    "profile_conversion = profile_conversion.sort_values('Profile_Completed')\n",
    "\n",
    "print(\"\\nConversion Rates by Profile Completion Level:\")\n",
    "print(profile_conversion)\n",
    "\n",
    "# Create barplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=profile_conversion, x='Profile_Completed', y='Conversion_Rate', palette='coolwarm', order=profile_order)\n",
    "plt.title('Conversion Rate by Profile Completion Level')\n",
    "plt.ylabel('Conversion Rate (%)')\n",
    "plt.xlabel('Profile Completion Level')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d1c2c1",
   "metadata": {},
   "source": [
    "**Question 5 Insights:**\n",
    "\n",
    "- Report actual conversion rates: \"Low profile completion: [X]%, Medium: [Y]%, High: [Z]%.\"\n",
    "- Analyze the trend: \"Conversion rate [increases/decreases/stays constant] as profile completion increases from Low to High.\"\n",
    "- Calculate the difference: \"High profile completion shows [X]% higher conversion than Low profile completion.\"\n",
    "- Provide business insight: \"This indicates [interpretation based on actual data]. We should [specific recommendation].\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9d425a",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- Report actual statistics (mean, median, min, max) for numeric features\n",
    "- Identify any obvious outliers or unusual distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e1911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for duplicate values in the data\n",
    "data.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bac23fd",
   "metadata": {},
   "source": [
    "**Sanity Checks:**\n",
    "\n",
    "- Report actual count of duplicate rows found\n",
    "- Document any missing values found and their implications\n",
    "- Check for data quality issues\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c323768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping ID column as it is an identifier and will not add value to the analysis\n",
    "data = data.drop(columns=[\"ID\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46eac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical value counts\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(data[col].value_counts(1))\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756be97c",
   "metadata": {},
   "source": [
    "**Target Variable Distribution:**\n",
    "\n",
    "- Report actual class distribution of `status` variable\n",
    "- Calculate and document the exact ratio (e.g., \"The target variable shows a X%/Y% split between converted (1) and unconverted (0) leads\")\n",
    "- Based on this actual distribution, determine which metrics are most appropriate (if imbalanced, emphasize Recall; if balanced, accuracy may be sufficient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-juice",
   "metadata": {
    "id": "persistent-juice"
   },
   "outputs": [],
   "source": [
    "# View the first 5 rows of the dataset\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seasonal-calibration",
   "metadata": {
    "id": "seasonal-calibration"
   },
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "- EDA is an important part of any project involving data.\n",
    "- It is important to investigate and understand the data better before building a model with it.\n",
    "- A few questions have been mentioned below which will help you approach the analysis in the right manner and generate insights from the data.\n",
    "- A thorough analysis of the data, in addition to the questions mentioned below, should be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-brother",
   "metadata": {
    "id": "approved-brother"
   },
   "source": [
    "**Questions**\n",
    "1. Leads will have different expectations from the outcome of the course and the current occupation may play a key role in getting them to participate in the program. Find out how current occupation affects lead status.\n",
    "2. The company's first impression on the customer must have an impact. Do the first channels of interaction have an impact on the lead status? \n",
    "3. The company uses multiple modes to interact with prospects. Which way of interaction works best? \n",
    "4. The company gets leads from various channels such as print media, digital media, referrals, etc. Which of these channels have the highest lead conversion rate?\n",
    "5. People browsing the website or mobile application are generally required to create a profile by sharing their personal data before they can access additional information.Does having more details about a prospect increase the chances of conversion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87690d8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "alleged-spirituality",
   "metadata": {
    "id": "alleged-spirituality"
   },
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- Missing value treatment (if needed)\n",
    "- Feature engineering (if needed)\n",
    "- Outlier detection and treatment (if needed)\n",
    "- Preparing data for modeling \n",
    "- Any other preprocessing steps (if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "increasing-louisiana",
   "metadata": {
    "id": "increasing-louisiana"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "amazing-fluid",
   "metadata": {
    "id": "amazing-fluid"
   },
   "source": [
    "## Building a Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "neither-hydrogen",
   "metadata": {
    "id": "neither-hydrogen"
   },
   "outputs": [],
   "source": [
    "# Function to compute different metrics to check performance of a classification model\n",
    "def model_performance_classification(model, predictors, target):\n",
    "    \"\"\"\n",
    "    Function to compute different metrics to check classification model performance\n",
    "    \n",
    "    model: classifier\n",
    "    predictors: independent variables\n",
    "    target: dependent variable\n",
    "    \"\"\"\n",
    "    pred = model.predict(predictors)\n",
    "    acc = accuracy_score(target, pred)\n",
    "    recall = recall_score(target, pred)\n",
    "    precision = precision_score(target, pred)\n",
    "    f1 = f1_score(target, pred)\n",
    "    \n",
    "    # Creating a dataframe of metrics\n",
    "    df_perf = pd.DataFrame(\n",
    "        {\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": precision,\n",
    "            \"Recall\": recall,\n",
    "            \"F1\": f1,\n",
    "        },\n",
    "        index=[0],\n",
    "    )\n",
    "    \n",
    "    return df_perf\n",
    "\n",
    "# Build Decision Tree Classifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=1)\n",
    "\n",
    "# Fit model on training data\n",
    "dt_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "print(\"Decision Tree Model Performance on Test Set:\")\n",
    "print(\"=\" * 80)\n",
    "dt_perf = model_performance_classification(dt_classifier, X_test, y_test)\n",
    "print(dt_perf)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\" * 80)\n",
    "cm = confusion_matrix(y_test, dt_classifier.predict(X_test))\n",
    "print(cm)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Decision Tree - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, dt_classifier.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f2418d",
   "metadata": {},
   "source": [
    "**Decision Tree Model Performance:**\n",
    "\n",
    "- Report actual metrics: \"Decision Tree achieves Accuracy: X%, Precision: Y%, Recall: Z%, F1: W%\"\n",
    "- Display and interpret confusion matrix: \"The model correctly predicts [X] conversions and [Y] non-conversions. It has [Z] false positives and [W] false negatives.\"\n",
    "- Interpret model performance: \"The model shows [strength/weakness] in [specific metric], which is [important/less critical] for lead conversion prediction.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ef379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Decision Tree using GridSearchCV\n",
    "print(\"Hyperparameter Tuning for Decision Tree\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "# Use f1_score as the scoring metric (balanced metric for classification)\n",
    "dt_grid = GridSearchCV(\n",
    "    estimator=DecisionTreeClassifier(random_state=1),\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "dt_grid.fit(X_train, y_train)\n",
    "\n",
    "# Extract best estimator and hyperparameters\n",
    "dt_tuned = dt_grid.best_estimator_\n",
    "print(f\"\\nBest hyperparameters: {dt_grid.best_params_}\")\n",
    "print(f\"Best cross-validation score (F1): {dt_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned model on test set\n",
    "print(\"\\nTuned Decision Tree Model Performance on Test Set:\")\n",
    "print(\"=\" * 80)\n",
    "dt_tuned_perf = model_performance_classification(dt_tuned, X_test, y_test)\n",
    "print(dt_tuned_perf)\n",
    "\n",
    "# Compare with untuned model\n",
    "print(\"\\nComparison: Untuned vs Tuned Decision Tree\")\n",
    "print(\"=\" * 80)\n",
    "comparison_dt = pd.concat([dt_perf.add_suffix('_Untuned'), dt_tuned_perf.add_suffix('_Tuned')], axis=1)\n",
    "print(comparison_dt)\n",
    "\n",
    "# Confusion Matrix for tuned model\n",
    "print(\"\\nTuned Model - Confusion Matrix:\")\n",
    "print(\"=\" * 80)\n",
    "cm_tuned = confusion_matrix(y_test, dt_tuned.predict(X_test))\n",
    "print(cm_tuned)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_tuned, annot=True, fmt='d', cmap='Greens', cbar=False)\n",
    "plt.title('Tuned Decision Tree - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "limited-strengthening",
   "metadata": {
    "id": "limited-strengthening"
   },
   "source": [
    "## Model Performance evaluation and improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a15ab8",
   "metadata": {},
   "source": [
    "**Decision Tree Tuning Results:**\n",
    "\n",
    "- Report best hyperparameters found: \"GridSearchCV selected: [actual parameter values]\"\n",
    "- Compare tuned vs untuned performance with exact metrics: \"Tuning improved [Metric] from X% to Y%\"\n",
    "- Report final Decision Tree performance: \"After tuning, Decision Tree achieves Accuracy: X%, Precision: Y%, Recall: Z%, F1: W%\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-elements",
   "metadata": {
    "id": "ambient-elements"
   },
   "outputs": [],
   "source": [
    "# Build Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "\n",
    "# Fit model on training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test data\n",
    "print(\"Random Forest Model Performance on Test Set:\")\n",
    "print(\"=\" * 80)\n",
    "rf_perf = model_performance_classification(rf_classifier, X_test, y_test)\n",
    "print(rf_perf)\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(\"=\" * 80)\n",
    "cm_rf = confusion_matrix(y_test, rf_classifier.predict(X_test))\n",
    "print(cm_rf)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Oranges', cbar=False)\n",
    "plt.title('Random Forest - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(\"=\" * 80)\n",
    "print(classification_report(y_test, rf_classifier.predict(X_test)))\n",
    "\n",
    "# Feature Importance Visualization\n",
    "print(\"\\nFeature Importance Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "importances = rf_classifier.feature_importances_\n",
    "feature_names = X_train.columns\n",
    "\n",
    "# Create a dataframe for feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance_df.head(10))\n",
    "\n",
    "# Create horizontal bar chart showing top features\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features = feature_importance_df.head(15)\n",
    "sns.barplot(data=top_features, y='Feature', x='Importance', palette='viridis')\n",
    "plt.title('Top 15 Feature Importances - Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c47c07",
   "metadata": {
    "id": "amazing-fluid"
   },
   "source": [
    "## Building a Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376370c6",
   "metadata": {},
   "source": [
    "**Random Forest Model Performance:**\n",
    "\n",
    "- Report actual metrics: \"Random Forest achieves Accuracy: X%, Precision: Y%, Recall: Z%, F1: W%\"\n",
    "- Display and interpret confusion matrix\n",
    "- Report top 5-10 most important features with their actual importance scores: \"The model identifies [Feature 1] (importance: X), [Feature 2] (importance: Y), and [Feature 3] (importance: Z) as the strongest predictors of conversion.\"\n",
    "- Provide business interpretation: \"This indicates that [interpretation based on actual feature names and importance values].\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter Tuning for Random Forest using GridSearchCV\n",
    "print(\"Hyperparameter Tuning for Random Forest\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Use f1_score as the scoring metric\n",
    "rf_grid = GridSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=1),\n",
    "    param_grid=param_grid_rf,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit grid search\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Extract best estimator and hyperparameters\n",
    "rf_tuned = rf_grid.best_estimator_\n",
    "print(f\"\\nBest hyperparameters: {rf_grid.best_params_}\")\n",
    "print(f\"Best cross-validation score (F1): {rf_grid.best_score_:.4f}\")\n",
    "\n",
    "# Evaluate tuned model on test set\n",
    "print(\"\\nTuned Random Forest Model Performance on Test Set:\")\n",
    "print(\"=\" * 80)\n",
    "rf_tuned_perf = model_performance_classification(rf_tuned, X_test, y_test)\n",
    "print(rf_tuned_perf)\n",
    "\n",
    "# Compare with untuned Random Forest\n",
    "print(\"\\nComparison: Untuned vs Tuned Random Forest\")\n",
    "print(\"=\" * 80)\n",
    "comparison_rf = pd.concat([rf_perf.add_suffix('_Untuned'), rf_tuned_perf.add_suffix('_Tuned')], axis=1)\n",
    "print(comparison_rf)\n",
    "\n",
    "# Confusion Matrix for tuned model\n",
    "print(\"\\nTuned Random Forest - Confusion Matrix:\")\n",
    "print(\"=\" * 80)\n",
    "cm_rf_tuned = confusion_matrix(y_test, rf_tuned.predict(X_test))\n",
    "print(cm_rf_tuned)\n",
    "\n",
    "# Visualize confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm_rf_tuned, annot=True, fmt='d', cmap='Purples', cbar=False)\n",
    "plt.title('Tuned Random Forest - Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Final Model Comparison: Decision Tree (tuned) vs Random Forest (tuned)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"Final Model Comparison: Decision Tree (Tuned) vs Random Forest (Tuned)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Create comparison table\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Decision Tree (Tuned)': [\n",
    "        dt_tuned_perf['Accuracy'].values[0],\n",
    "        dt_tuned_perf['Precision'].values[0],\n",
    "        dt_tuned_perf['Recall'].values[0],\n",
    "        dt_tuned_perf['F1'].values[0]\n",
    "    ],\n",
    "    'Random Forest (Tuned)': [\n",
    "        rf_tuned_perf['Accuracy'].values[0],\n",
    "        rf_tuned_perf['Precision'].values[0],\n",
    "        rf_tuned_perf['Recall'].values[0],\n",
    "        rf_tuned_perf['F1'].values[0]\n",
    "    ]\n",
    "}, index=['Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "print(model_comparison)\n",
    "\n",
    "# Visualize comparison\n",
    "model_comparison.T.plot(kind='bar', figsize=(10, 6))\n",
    "plt.title('Model Performance Comparison')\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Model')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(loc='best')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature Importance from tuned Random Forest\n",
    "print(\"\\nTop 10 Features from Tuned Random Forest:\")\n",
    "print(\"=\" * 80)\n",
    "importances_tuned = rf_tuned.feature_importances_\n",
    "feature_importance_tuned_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances_tuned\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(feature_importance_tuned_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b79e39",
   "metadata": {},
   "source": [
    "**Random Forest Tuning and Model Comparison:**\n",
    "\n",
    "- Report best hyperparameters found: \"GridSearchCV selected: [actual parameter values]\"\n",
    "- Compare tuned vs untuned performance: \"Tuning improved [Metric] from X% to Y%\"\n",
    "- Compare both models: \"Decision Tree (tuned) achieves Accuracy: X%, Precision: Y%, Recall: Z%, F1: W%. Random Forest (tuned) achieves Accuracy: A%, Precision: B%, Recall: C%, F1: D%.\"\n",
    "- Make final model selection: \"Based on comparison, [Model Name] shows best performance with [specific metrics]. This model is chosen because [specific reason based on actual metrics and business requirements].\"\n",
    "- Update feature importance: Report top features from final model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa44ec4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11bc14ca",
   "metadata": {},
   "source": [
    "## Model Performance evaluation and improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f89cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc5725c1",
   "metadata": {},
   "source": [
    "## Actionable Insights and Recommendations\n",
    "\n",
    "Based on the comprehensive analysis of the ExtraaLearn leads dataset, the following insights and recommendations are provided. All insights are data-driven from the actual analysis performed.\n",
    "\n",
    "### 1. Key Conversion Drivers\n",
    "\n",
    "Based on feature importance analysis from the Random Forest model, the top factors that drive conversion are:\n",
    "\n",
    "- **[Top Feature 1]** (importance: [X]) - [Interpretation]\n",
    "- **[Top Feature 2]** (importance: [Y]) - [Interpretation]\n",
    "- **[Top Feature 3]** (importance: [Z]) - [Interpretation]\n",
    "\n",
    "Analysis reveals that [Feature X] is the strongest predictor (importance: Y). Leads with [characteristic] show [Z]% conversion rate vs [W]% for others.\n",
    "\n",
    "### 2. Profile of a High-Value Lead\n",
    "\n",
    "Analysis of top-converting leads shows they have:\n",
    "- **[Feature 1]** = [value/category from actual data]\n",
    "- **[Feature 2]** = [value/category from actual data]\n",
    "- **[Feature 3]** = [value/category from actual data]\n",
    "\n",
    "This profile represents [X]% of converted leads.\n",
    "\n",
    "### 3. Marketing Channel Effectiveness\n",
    "\n",
    "Based on the media flag analysis (Question 4), the following channels drive conversion:\n",
    "\n",
    "- **[Channel X]**: [Y]% conversion rate\n",
    "- **[Channel Z]**: [W]% conversion rate\n",
    "- **[Channel A]**: [B]% conversion rate\n",
    "\n",
    "Given that [Channel X] shows [Y]% conversion vs [Z]% average, we recommend [specific marketing action].\n",
    "\n",
    "### 4. Interaction Strategy Recommendations\n",
    "\n",
    "Based on Question 3 analysis (last_activity vs conversion):\n",
    "\n",
    "- **Email Activity**: [X]% conversion rate\n",
    "- **Phone Activity**: [Y]% conversion rate\n",
    "- **Website Activity**: [Z]% conversion rate\n",
    "\n",
    "Given that [Activity X] shows [Y]% conversion, we recommend [specific action].\n",
    "\n",
    "### 5. Profile Completion Strategy\n",
    "\n",
    "Based on Question 5 analysis:\n",
    "\n",
    "- **Low profile completion**: [X]% conversion\n",
    "- **Medium profile completion**: [Y]% conversion\n",
    "- **High profile completion**: [Z]% conversion\n",
    "\n",
    "Analysis shows that High profile completion leads to [X]% higher conversion than Low profile completion. We should [specific recommendation].\n",
    "\n",
    "### 6. Model Deployment Strategy\n",
    "\n",
    "**Final Model Performance:**\n",
    "- Selected Model: [Decision Tree / Random Forest]\n",
    "- Accuracy: [X]%\n",
    "- Precision: [Y]%\n",
    "- Recall: [Z]%\n",
    "- F1-Score: [W]%\n",
    "\n",
    "The model can predict conversion probability for new leads, allowing the sales team to prioritize [X] leads, potentially improving conversion rate by [estimated impact based on model performance]%.\n",
    "\n",
    "**Model Limitations:**\n",
    "- [List any limitations identified]\n",
    "- [Monitoring needs]\n",
    "\n",
    "### 7. Resource Allocation Recommendations\n",
    "\n",
    "Based on all findings:\n",
    "\n",
    "1. **Marketing Budget Allocation:**\n",
    "   - Allocate [X]% more resources to [Channel with highest conversion]\n",
    "   - Reduce investment in [Channel with low conversion] by [Y]%\n",
    "\n",
    "2. **Sales Team Focus:**\n",
    "   - Prioritize leads with [characteristics from high-value profile]\n",
    "   - Focus on [interaction method with highest conversion]\n",
    "\n",
    "3. **Product Development:**\n",
    "   - [Recommendations based on profile completion findings]\n",
    "   - [Recommendations based on feature importance]\n",
    "\n",
    "**Expected Impact:**\n",
    "Given that [finding from actual analysis], allocating [X]% more resources to [specific area] is expected to improve overall conversion rate by approximately [Y]%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nasty-retailer",
   "metadata": {
    "id": "nasty-retailer"
   },
   "source": [
    "## Actionable Insights and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-prediction",
   "metadata": {
    "id": "amino-prediction"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ExtraaLearn_Project_Template_Notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
